# OpenLM-Awesome

## Open Large Language Models

| Model | Stars | Organization | Language[^1] | Style | Checkpoints |
| --- | --- | --- | --- | --- | --- |
| [LLaMa](https://github.com/facebookresearch/llama)[^2] | ![](https://img.shields.io/github/stars/facebookresearch/llama.svg) | Meta AI | Multi-Language | Decoder-style | [7B](https://huggingface.co/decapoda-research/llama-7b-hf) & [13B](https://huggingface.co/decapoda-research/llama-13b-hf) & [30B](https://huggingface.co/decapoda-research/llama-30b-hf) & [65B](https://huggingface.co/decapoda-research/llama-65b-hf) |
| [OPT](https://github.com/facebookresearch/metaseq) | ![](https://img.shields.io/github/stars/facebookresearch/metaseq.svg) | Meta AI | English | Decoder-style | [125M](https://huggingface.co/facebook/opt-125m) & [350M](https://huggingface.co/facebook/opt-350m) & [1.3B](https://huggingface.co/facebook/opt-1.3b) & [2.7B](https://huggingface.co/facebook/opt-2.7b) & [6.7B](https://huggingface.co/facebook/opt-6.7b) & [13B](https://huggingface.co/facebook/opt-13b) & [30B](https://huggingface.co/facebook/opt-30b) & [66B](https://huggingface.co/facebook/opt-66b) |
| BLOOM | -- | BigScience | Multi-Language | Decoder-style | [560m](https://huggingface.co/bigscience/bloom-560m) & [1.1B](https://huggingface.co/bigscience/bloom-1b1) & [1.7B](https://huggingface.co/bigscience/bloom-1b7) & [3B](https://huggingface.co/bigscience/bloom-3b3) & [7.1B](https://huggingface.co/bigscience/bloom-7b1) |


[^1]: Languages used in pretraining texts.

[^2]: The LLaMa models are currently not publicly available, but the checkpoints can be accessed via the following link on the [Decapoda Research](https://huggingface.co/decapoda-research) page of HuggingFace.